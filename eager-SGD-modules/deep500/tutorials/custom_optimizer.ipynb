{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/deep500/deep500.git\n",
      "  Cloning https://github.com/deep500/deep500.git to /tmp/pip-req-build-ytntplqd\n",
      "Requirement already satisfied (use --upgrade to upgrade): deep500==0.2.0 from git+https://github.com/deep500/deep500.git in /home/xl/d500/lib/python3.6/site-packages\n",
      "Requirement already satisfied: onnx in /home/xl/d500/lib/python3.6/site-packages (from deep500==0.2.0) (1.4.1)\n",
      "Requirement already satisfied: numpy in /home/xl/d500/lib/python3.6/site-packages (from deep500==0.2.0) (1.16.1)\n",
      "Requirement already satisfied: tqdm in /home/xl/d500/lib/python3.6/site-packages (from deep500==0.2.0) (4.31.1)\n",
      "Requirement already satisfied: cmake in /home/xl/d500/lib/python3.6/site-packages (from deep500==0.2.0) (3.13.3)\n",
      "Requirement already satisfied: typing>=3.6.4 in /home/xl/d500/lib/python3.6/site-packages (from onnx->deep500==0.2.0) (3.6.6)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /home/xl/d500/lib/python3.6/site-packages (from onnx->deep500==0.2.0) (3.7.2)\n",
      "Requirement already satisfied: six in /home/xl/d500/lib/python3.6/site-packages (from onnx->deep500==0.2.0) (1.12.0)\n",
      "Requirement already satisfied: protobuf in /home/xl/d500/lib/python3.6/site-packages (from onnx->deep500==0.2.0) (3.6.1)\n",
      "Requirement already satisfied: setuptools in /home/xl/d500/lib/python3.6/site-packages (from protobuf->onnx->deep500==0.2.0) (40.8.0)\n",
      "Building wheels for collected packages: deep500\n",
      "  Building wheel for deep500 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-sfsry7ti/wheels/e3/8d/95/a4c60f0d7b00827c3a14476a62ba5c961876c158841e47cc36\n",
      "Successfully built deep500\n"
     ]
    }
   ],
   "source": [
    "# Install Deep500\n",
    "! pip install git+https://github.com/deep500/deep500.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Deep500\n",
    "import deep500 as d5\n",
    "import deep500.datasets as d5ds\n",
    "import deep500.networks as d5nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Get dataset size\n",
    "mnist_shape = d5ds.dataset_shape('mnist')\n",
    "print(mnist_shape)\n",
    "classes, c, h, w = mnist_shape\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xl/d500/lib/python3.6/site-packages/deep500/networks/pytorch_mnist.py:11: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(m.weight, gain=np.sqrt(2))\n",
      "/home/xl/d500/lib/python3.6/site-packages/deep500/networks/pytorch_mnist.py:12: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(m.bias, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%0 : Float(128, 1, 28, 28)\n",
      "      %1 : Float(10, 1, 5, 5)\n",
      "      %2 : Float(10)\n",
      "      %3 : Float(20, 10, 5, 5)\n",
      "      %4 : Float(20)\n",
      "      %5 : Float(50, 320)\n",
      "      %6 : Float(50)\n",
      "      %7 : Float(10, 50)\n",
      "      %8 : Float(10)) {\n",
      "  %9 : Float(128, 10, 24, 24) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[1, 1]](%0, %1, %2), scope: Net/Conv2d[conv1]\n",
      "  %10 : Float(128, 10, 12, 12) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%9), scope: Net\n",
      "  %11 : Float(128, 10, 12, 12) = onnx::Relu(%10), scope: Net\n",
      "  %12 : Float(128, 20, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[1, 1]](%11, %3, %4), scope: Net/Conv2d[conv2]\n",
      "  %13 : Float(128, 20, 4, 4) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%12), scope: Net\n",
      "  %14 : Float(128, 20, 4, 4) = onnx::Relu(%13), scope: Net\n",
      "  %15 : Tensor = onnx::Constant[value=  -1  320 [ CPULongType{2} ]](), scope: Net\n",
      "  %16 : Float(128, 320) = onnx::Reshape(%14, %15), scope: Net\n",
      "  %17 : Float(128, 50) = onnx::Gemm[alpha=1, beta=1, transB=1](%16, %5, %6), scope: Net/Linear[fc1]\n",
      "  %18 : Float(128, 50) = onnx::Relu(%17), scope: Net\n",
      "  %19 : Float(128, 10) = onnx::Gemm[alpha=1, beta=1, transB=1](%18, %7, %8), scope: Net/Linear[fc2]\n",
      "  %20 : Float(128, 10) = onnx::Softmax[axis=1](%19), scope: Net\n",
      "  return (%20);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create deep neural network\n",
    "onnx_file = d5nt.export_network('simple_cnn', BATCH_SIZE, classes=classes,\n",
    "                                shape=(c, h, w))\n",
    "model = d5.parser.load_and_parse_model(onnx_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 20\n"
     ]
    }
   ],
   "source": [
    "# Get model input/output\n",
    "INPUT_NODE = model.get_input_nodes()[0].name\n",
    "OUTPUT_NODE = model.get_output_nodes()[0].name\n",
    "print(INPUT_NODE, OUTPUT_NODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0.00B [00:00, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train_images...\n",
      "/tmp/mnist/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9.46MB [00:02, 4.94MB/s]                            \n",
      "0.00B [00:00, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading test_images...\n",
      "/tmp/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1.58MB [00:00, 1.75MB/s]                            \n",
      " 28%|██▊       | 8.00k/28.2k [00:00<00:00, 43.0kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train_labels...\n",
      "/tmp/mnist/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32.0kB [00:00, 116kB/s]                             \n",
      "8.00kB [00:00, 43.7kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading test_labels...\n",
      "/tmp/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Download complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up dataset\n",
    "train_set, test_set = d5ds.load_dataset('mnist', INPUT_NODE, 'labels')\n",
    "model.add_operation(d5.ops.SoftmaxCrossEntropy([OUTPUT_NODE, 'labels'], 'loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset samplers\n",
    "train_sampler = d5.ShuffleSampler(train_set, BATCH_SIZE)\n",
    "test_sampler = d5.ShuffleSampler(test_set, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up network executor\n",
    "from deep500.frameworks import tensorflow as d5fw\n",
    "executor = d5fw.from_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up opimizer\n",
    "from deep500.frameworks import reference as d5ref\n",
    "optimizer = d5ref.GradientDescent(executor, 'loss', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 78/78 [00:02<00:00, 38.60it/s, accuracy=3.77, test_loss=2.28]\n",
      "Training (epoch 1/2): 100%|██████████| 468/468 [00:21<00:00, 21.48it/s, batch_acc=92.2, loss_avg=0.48] \n",
      "Testing: 100%|██████████| 78/78 [00:01<00:00, 55.77it/s, accuracy=94, test_loss=0.175]  \n",
      "Training (epoch 2/2): 100%|██████████| 468/468 [00:20<00:00, 22.90it/s, batch_acc=99.2, loss_avg=0.108]\n",
      "Testing: 100%|██████████| 78/78 [00:01<00:00, 59.61it/s, accuracy=97.8, test_loss=0.0669]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingAccuracy: 96.64963942307692\n",
      "TestAccuracy: 97.83653846153847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[96.64963942307692, 97.83653846153847]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "d5.test_training(executor, train_sampler, test_sampler, optimizer, \n",
    "                 EPOCHS, BATCH_SIZE, OUTPUT_NODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 78/78 [00:01<00:00, 49.72it/s, accuracy=3.77, test_loss=2.28]\n",
      "Training (epoch 1/2): 100%|██████████| 468/468 [00:21<00:00, 21.64it/s, batch_acc=96.1, loss_avg=0.399]\n",
      "Testing: 100%|██████████| 78/78 [00:01<00:00, 57.45it/s, accuracy=97.2, test_loss=0.0889]\n",
      "Training (epoch 2/2): 100%|██████████| 468/468 [00:21<00:00, 21.50it/s, batch_acc=97.7, loss_avg=0.0766]\n",
      "Testing: 100%|██████████| 78/78 [00:01<00:00, 57.12it/s, accuracy=98.1, test_loss=0.0559]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingAccuracy: 97.54607371794872\n",
      "TestAccuracy: 98.08693910256412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[97.54607371794872, 98.08693910256412]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class StochasticUpdateRule(d5ref.GradientDescent):\n",
    "    def update_rule(self, grad, old_param, param_name):\n",
    "        return old_param - (np.random.random_sample() * self.lr) * grad\n",
    "\n",
    "# Reload model\n",
    "model = d5.parser.load_and_parse_model(onnx_file)\n",
    "model.add_operation(d5.ops.SoftmaxCrossEntropy([OUTPUT_NODE, 'labels'], 'loss'))\n",
    "executor = d5fw.from_model(model) \n",
    "\n",
    "# Replace optimizer\n",
    "optimizer = StochasticUpdateRule(executor, 'loss', 0.5)\n",
    "d5.test_training(executor, train_sampler, test_sampler, optimizer, \n",
    "                 EPOCHS, BATCH_SIZE, OUTPUT_NODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}